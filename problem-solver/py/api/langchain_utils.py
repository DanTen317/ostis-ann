from langchain_community.chat_models import ChatOllama
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from chroma_utils import vectorstore
from langchain_core.callbacks import BaseCallbackHandler
from typing import Any, Dict, List
import json
from datetime import datetime

from langchain_core.callbacks import CallbackManager


class DetailedCallbackHandler(BaseCallbackHandler):
    """–ü–æ–¥—Ä–æ–±–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–±—ã—Ç–∏–π –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ä–∞–±–æ—Ç—ã LangChain."""

    def __init__(self, color_output: bool = True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞.
        
        Args:
            color_output: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ —Ü–≤–µ—Ç–Ω–æ–π –≤—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
        """
        super().__init__()
        self.color_output = color_output
        # ANSI –∫–æ–¥—ã —Ü–≤–µ—Ç–æ–≤
        self.colors = {
            'blue': '\033[94m',
            'green': '\033[92m',
            'yellow': '\033[93m',
            'red': '\033[91m',
            'end': '\033[0m'
        } if color_output else dict.fromkeys(['blue', 'green', 'yellow', 'red', 'end'], '')

    def _format_time(self) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏."""
        return datetime.now().strftime("%H:%M:%S")

    def _print_colored(self, text: str, color: str) -> None:
        """–í—ã–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ —Å —Ü–≤–µ—Ç–æ–º."""
        print(f"{self.colors[color]}{text}{self.colors['end']}")

    def _format_json(self, data: Any) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —á–∏—Ç–∞–µ–º—ã–π JSON."""
        return json.dumps(data, ensure_ascii=False, indent=2)

    def on_llm_start(
            self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any
    ) -> None:
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ LLM."""
        self._print_colored(
            f"\nü§ñ [{self._format_time()}] –ó–∞–ø—É—Å–∫ LLM –º–æ–¥–µ–ª–∏ {serialized.get('name', 'Unknown')}",
            "blue"
        )
        for i, prompt in enumerate(prompts, 1):
            self._print_colored(f"\n–ó–∞–ø—Ä–æ—Å {i}:\n{prompt}", "yellow")

    def on_llm_end(self, response: Any, **kwargs: Any) -> None:
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã LLM."""
        self._print_colored(
            f"\n‚úÖ [{self._format_time()}] LLM –∑–∞–≤–µ—Ä—à–∏–ª–∞ —Ä–∞–±–æ—Ç—É\n–û—Ç–≤–µ—Ç: {response}",
            "green"
        )

    def on_llm_error(self, error: BaseException, **kwargs: Any) -> None:
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –æ—à–∏–±–∫–µ LLM."""
        self._print_colored(
            f"\n‚ùå [{self._format_time()}] –û—à–∏–±–∫–∞ LLM: {str(error)}",
            "red"
        )

    def on_chain_start(
            self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs: Any
    ) -> None:
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ —Ü–µ–ø–æ—á–∫–∏."""
        chain_type = serialized.get("name", "Unknown")
        self._print_colored(
            f"\n‚õìÔ∏è [{self._format_time()}] –ó–∞–ø—É—Å–∫ —Ü–µ–ø–æ—á–∫–∏: {chain_type}",
            "blue"
        )
        self._print_colored(
            f"–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\n{self._format_json(inputs)}",
            "yellow"
        )

    def on_chain_end(self, outputs: Dict[str, Any], **kwargs: Any) -> None:
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã —Ü–µ–ø–æ—á–∫–∏."""
        self._print_colored(
            f"\nüèÅ [{self._format_time()}] –¶–µ–ø–æ—á–∫–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞ —Ä–∞–±–æ—Ç—É",
            "green"
        )
        self._print_colored(
            f"–í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\n{self._format_json(outputs)}",
            "green"
        )

    def on_chain_error(self, error: BaseException, **kwargs: Any) -> None:
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –æ—à–∏–±–∫–µ –≤ —Ü–µ–ø–æ—á–∫–µ."""
        self._print_colored(
            f"\n‚ùå [{self._format_time()}] –û—à–∏–±–∫–∞ –≤ —Ü–µ–ø–æ—á–∫–µ: {str(error)}",
            "red"
        )

    def on_tool_start(
            self, serialized: Dict[str, Any], input_str: str, **kwargs: Any
    ) -> None:
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞."""
        self._print_colored(
            f"\nüîß [{self._format_time()}] –ó–∞–ø—É—Å–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞: {serialized.get('name', 'Unknown')}",
            "blue"
        )
        self._print_colored(f"–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {input_str}", "yellow")

    def on_tool_end(self, output: str, **kwargs: Any) -> None:
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞."""
        self._print_colored(
            f"\n‚úÖ [{self._format_time()}] –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É",
            "green"
        )
        self._print_colored(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {output}", "green")

    def on_tool_error(self, error: BaseException, **kwargs: Any) -> None:
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –æ—à–∏–±–∫–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞."""
        self._print_colored(
            f"\n‚ùå [{self._format_time()}] –û—à–∏–±–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞: {str(error)}",
            "red"
        )

    def on_retriever_start(
            self, serialized: Dict[str, Any], query: str, **kwargs: Any
    ) -> None:
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø–æ–∏—Å–∫–∞."""
        self._print_colored(
            f"\nüîç [{self._format_time()}] –ù–∞—á–∞–ª–æ –ø–æ–∏—Å–∫–∞",
            "blue"
        )
        self._print_colored(f"–ó–∞–ø—Ä–æ—Å: {query}", "yellow")

    def on_retriever_end(self, documents: List[Any], **kwargs: Any) -> None:
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –ø–æ–∏—Å–∫–∞."""
        self._print_colored(
            f"\nüìÑ [{self._format_time()}] –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(documents)}",
            "green"
        )
        for idx, doc in enumerate(documents, 1):
            self._print_colored(
                f"\n–î–æ–∫—É–º–µ–Ω—Ç {idx}:",
                "green"
            )
            if hasattr(doc, 'page_content'):
                self._print_colored(
                    f"–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {doc.page_content[:200]}...",
                    "yellow"
                )
            if hasattr(doc, 'metadata'):
                self._print_colored(
                    f"–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:\n{self._format_json(doc.metadata)}",
                    "yellow"
                )

    def on_retriever_error(self, error: BaseException, **kwargs: Any) -> None:
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –æ—à–∏–±–∫–µ –ø–æ–∏—Å–∫–∞."""
        self._print_colored(
            f"\n‚ùå [{self._format_time()}] –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {str(error)}",
            "red"
        )


retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

contextualize_q_system_prompt = (
    "Given a chat history and the latest user question "
    "which might reference context in the chat history, "
    "formulate a standalone question which can be understood "
    "without the chat history. Do NOT answer the question, "
    "just reformulate it if needed and otherwise return it as is."
)

contextualize_q_prompt = ChatPromptTemplate.from_messages([
    ("system", contextualize_q_system_prompt),
    MessagesPlaceholder("chat_history"),
    ("human", "{input}"),
])

qa_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful AI assistant. Use the following context to answer the user's question."),
    ("system", "Context: {context}"),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}")
])


def get_rag_chain(model="gemma3"):
    callbacks = [DetailedCallbackHandler()]
    callback_manager = CallbackManager(callbacks)

    llm = ChatOllama(model=model, callback_manager=callback_manager)
    history_aware_retriever = create_history_aware_retriever(
        llm,
        retriever,
        contextualize_q_prompt
    )
    question_answer_chain = create_stuff_documents_chain(
        llm,
        qa_prompt
    )

    rag_chain = create_retrieval_chain(
        history_aware_retriever,
        question_answer_chain
    )
    return rag_chain
